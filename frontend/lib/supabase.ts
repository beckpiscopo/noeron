/**
 * Supabase client for Noeron frontend
 * 
 * This replaces old JSON-based data loading with real-time database queries.
 */

import { createClient } from '@supabase/supabase-js'

// Environment variables (add these to .env.local)
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY

// Create client only if credentials are available
export const supabase = supabaseUrl && supabaseAnonKey 
  ? createClient(supabaseUrl, supabaseAnonKey)
  : null

// Log warning if Supabase is not configured
if (!supabase && typeof window !== 'undefined') {
  console.warn('⚠️ Supabase not configured. Add NEXT_PUBLIC_SUPABASE_URL and NEXT_PUBLIC_SUPABASE_ANON_KEY to .env.local')
  console.warn('Falling back to MCP tool for data loading.')
}

// ============================================================================
// Types (auto-generated by Supabase, but defined manually for now)
// ============================================================================

export interface Episode {
  id: number
  podcast_id: string
  title: string
  guest_name?: string
  podcast_series?: string
  duration_ms?: number
  published_date?: string
  audio_url?: string
  description?: string
  topics?: string[]
  created_at: string
  updated_at: string
}

export interface Claim {
  id: number
  podcast_id: string
  segment_claim_id?: string  // Format: "segment_key-index" (e.g., "lex_325|00:00:00.160|1-0")
  timestamp?: string
  start_ms?: number
  end_ms?: number
  claim_text: string
  distilled_claim?: string
  distilled_word_count?: number
  paper_id?: string
  paper_title?: string
  paper_url?: string
  section?: string
  rationale?: string
  confidence_score?: number
  claim_type?: string
  speaker_stance?: string
  needs_backing_because?: string
  context_tags?: Record<string, string>
  keywords?: string[]  // 2-4 key terms extracted from the claim
  verified?: boolean
  verification_details?: any
  created_at: string
  updated_at: string
}

export interface Paper {
  id: number
  paper_id: string
  title: string
  abstract?: string
  authors?: string[]
  year?: number
  venue?: string
  citation_count?: number
  url?: string
  arxiv_id?: string
  doi?: string
  full_text?: string
  created_at: string
  updated_at: string
}

// ============================================================================
// Bookmark Types
// ============================================================================

export type BookmarkType = 'claim' | 'paper' | 'snippet' | 'ai_insight' | 'image'

export interface Bookmark {
  id: string
  user_id: string
  bookmark_type: BookmarkType
  claim_id?: number
  paper_id?: string
  episode_id?: string
  snippet_text?: string
  start_ms?: number
  end_ms?: number
  title: string
  context_preview?: string
  tags?: string[]
  notes?: string
  // New fields for ai_insight and image types
  insight_source?: string  // For ai_insight: 'chat_response' | 'deep_dive' | etc.
  image_url?: string       // For image type
  image_caption?: string   // For image type
  // Quiz tracking
  quiz_enabled: boolean
  last_quizzed_at?: string
  quiz_score: number
  quiz_count: number
  created_at: string
  updated_at: string
}

export interface BookmarkWithDetails extends Bookmark {
  claim?: Claim
  paper?: Paper
}

// ============================================================================
// Notebook Synthesis Types
// ============================================================================

export interface NotebookSynthesisTheme {
  name: string
  description: string
}

export interface NotebookSynthesisConnection {
  episode_id: string
  episode_title?: string
  connection_type: string  // 'shared_paper' | 'shared_topic' | etc.
  details?: string
}

export interface NotebookSynthesis {
  id: string
  user_id: string
  episode_id: string
  synthesis_text: string
  themes?: NotebookSynthesisTheme[]
  connections?: NotebookSynthesisConnection[]
  generated_at: string
  bookmark_count_at_generation: number
  model_used: string
  is_stale: boolean
  created_at: string
  updated_at?: string
}

export interface EpisodeNotebookStats {
  episode_id: string
  total_items: number
  claim_count: number
  paper_count: number
  snippet_count: number
  ai_insight_count: number
  image_count: number
  last_updated: string
}

export interface QuizSession {
  id: string
  user_id: string
  started_at: string
  completed_at?: string
  total_questions: number
  correct_answers: number
  bookmarks_included: string[]
  created_at: string
}

export interface QuizQuestion {
  bookmark_id: string
  question_text: string
  question_type: 'recall' | 'concept' | 'application'
  answer: string
  source_text: string
}

// ============================================================================
// Taxonomy Cluster Types
// ============================================================================

export interface TaxonomyCluster {
  id: number
  cluster_id: number
  label: string
  description: string
  keywords: string[]
  position_x: number
  position_y: number
  centroid_embedding?: number[]
  paper_count: number
  primary_paper_count: number
  generated_at: string
  model_used?: string
  created_at: string
  updated_at: string
}

export interface ClusterNode {
  id: string                    // "cluster-0", "cluster-1", etc.
  cluster_id: number
  type: 'cluster'
  label: string
  description: string
  keywords: string[]
  x: number                     // UMAP position (0-1)
  y: number                     // UMAP position (0-1)
  size: number                  // paper_count for sizing
  primaryCount: number
  // Highlighting state (computed client-side)
  isHighlighted?: boolean
  isInNotebook?: boolean
  isInEpisode?: boolean
}

export interface PaperClusterAssignment {
  id: number
  paper_id: string
  cluster_id: number
  confidence: number            // GMM probability (0-1)
  is_primary: boolean
  position_x: number
  position_y: number
  created_at: string
  // Joined data
  papers?: Paper
  taxonomy_clusters?: TaxonomyCluster
}

export interface ClusterCoverage {
  cluster_id: number
  label: string
  description?: string
  keywords?: string[]
  position_x?: number
  position_y?: number
  claim_count: number
  unique_papers?: number
  avg_confidence: number
}

export interface NotebookClusterDistribution {
  cluster_id: number
  label: string
  description?: string
  position_x?: number
  position_y?: number
  bookmark_count: number
  claim_bookmarks: number
  paper_bookmarks: number
}

export interface EpisodeNotebookComparison {
  cluster_id: number
  label: string
  description?: string
  keywords?: string[]
  position_x?: number
  position_y?: number
  in_episode: boolean
  episode_claim_count: number
  in_notebook: boolean
  notebook_item_count: number
}

export interface ClusterComparisonSummary {
  episode_cluster_count: number
  notebook_cluster_count: number
  new_territory_count: number
  overlap_count: number
  total_clusters: number
}

export interface ClusterBubbleMapData {
  nodes: ClusterNode[]
  bounds: { minX: number; maxX: number; minY: number; maxY: number }
  cluster_count: number
}

// ============================================================================
// Query Functions
// ============================================================================

/**
 * Get all episodes, sorted by published date
 */
export async function getEpisodes() {
  if (!supabase) return []
  
  const { data, error } = await supabase
    .from('episodes')
    .select('*')
    .order('published_date', { ascending: false })
  
  if (error) throw error
  return data as Episode[]
}

/**
 * Get a single episode by podcast_id
 */
export async function getEpisode(podcastId: string) {
  if (!supabase) return null
  
  const { data, error } = await supabase
    .from('episodes')
    .select('*')
    .eq('podcast_id', podcastId)
    .single()
  
  if (error) throw error
  return data as Episode
}

/**
 * Get all claims for an episode, ordered by timestamp
 * Excludes claims marked as duplicates (duplicate_of IS NULL)
 */
export async function getClaimsForEpisode(podcastId: string) {
  if (!supabase) return []

  const { data, error } = await supabase
    .from('claims')
    .select('*')
    .eq('podcast_id', podcastId)
    .is('duplicate_of', null)
    .order('start_ms', { ascending: true })

  if (error) throw error
  return data as Claim[]
}

/**
 * Get claims in a time range (for "Live Research Stream" view)
 * Excludes claims marked as duplicates
 *
 * @param podcastId - Episode to query
 * @param currentTimeMs - Current playback position in milliseconds
 * @param windowMs - Time window in milliseconds (default: 30 seconds)
 */
export async function getClaimsInTimeRange(
  podcastId: string,
  currentTimeMs: number,
  windowMs: number = 30000
) {
  if (!supabase) return []

  const startMs = Math.max(0, currentTimeMs - windowMs)
  const endMs = currentTimeMs + windowMs

  const { data, error } = await supabase
    .from('claims')
    .select('*')
    .eq('podcast_id', podcastId)
    .is('duplicate_of', null)
    .gte('start_ms', startMs)
    .lte('start_ms', endMs)
    .order('start_ms', { ascending: true })

  if (error) throw error
  return data as Claim[]
}

/**
 * Search claims by text (full-text search)
 * Excludes claims marked as duplicates
 */
export async function searchClaims(query: string, podcastId?: string) {
  if (!supabase) return []

  let queryBuilder = supabase
    .from('claims')
    .select('*')
    .is('duplicate_of', null)
    .or(`claim_text.ilike.%${query}%,distilled_claim.ilike.%${query}%`)

  if (podcastId) {
    queryBuilder = queryBuilder.eq('podcast_id', podcastId)
  }

  const { data, error } = await queryBuilder

  if (error) throw error
  return data as Claim[]
}

/**
 * Get claims by organism or topic (using context_tags)
 * Excludes claims marked as duplicates
 */
export async function getClaimsByTag(
  tagKey: string,
  tagValue: string,
  podcastId?: string
) {
  if (!supabase) return []

  let queryBuilder = supabase
    .from('claims')
    .select('*')
    .is('duplicate_of', null)
    .contains('context_tags', { [tagKey]: tagValue })

  if (podcastId) {
    queryBuilder = queryBuilder.eq('podcast_id', podcastId)
  }

  const { data, error } = await queryBuilder

  if (error) throw error
  return data as Claim[]
}

/**
 * Get statistics for an episode
 */
export async function getEpisodeStats(podcastId: string) {
  if (!supabase) return null
  
  const { data, error } = await supabase
    .from('episode_stats')
    .select('*')
    .eq('podcast_id', podcastId)
    .single()
  
  if (error) throw error
  return data
}

/**
 * Subscribe to real-time updates for claims
 * (useful if you want to show new distillations as they're generated)
 */
export function subscribeToClaimsForEpisode(
  podcastId: string,
  callback: (claim: Claim) => void
) {
  if (!supabase) {
    console.warn('⚠️ Cannot subscribe to real-time updates: Supabase not configured')
    return () => {} // Return no-op unsubscribe function
  }
  
  const channel = supabase
    .channel(`claims:${podcastId}`)
    .on(
      'postgres_changes',
      {
        event: '*',
        schema: 'public',
        table: 'claims',
        filter: `podcast_id=eq.${podcastId}`,
      },
      (payload) => {
        callback(payload.new as Claim)
      }
    )
    .subscribe()
  
  return () => {
    supabase.removeChannel(channel)
  }
}

// ============================================================================
// Bookmark Query Functions
// ============================================================================

/**
 * Get the current user ID from Supabase auth
 * Throws an error if not authenticated (required for user-specific data)
 */
async function getCurrentUserId(): Promise<string> {
  if (!supabase) {
    throw new Error('Supabase client not configured')
  }

  const { data: { user }, error } = await supabase.auth.getUser()

  if (error) {
    console.error('Error getting user:', error)
    throw new Error(`Authentication error: ${error.message}`)
  }

  if (!user?.id) {
    throw new Error('Not authenticated. Please sign in to use this feature.')
  }

  console.log('[getCurrentUserId] User ID:', user.id)
  return user.id
}

/**
 * Get all bookmarks for the current user
 */
export async function getBookmarks(type?: BookmarkType): Promise<Bookmark[]> {
  if (!supabase) return []

  const userId = await getCurrentUserId()
  let query = supabase
    .from('bookmarks')
    .select('*')
    .eq('user_id', userId)
    .order('created_at', { ascending: false })

  if (type) {
    query = query.eq('bookmark_type', type)
  }

  const { data, error } = await query
  if (error) throw error
  return data as Bookmark[]
}

/**
 * Get bookmarks with full details (joined with claims/papers)
 */
export async function getBookmarksWithDetails(): Promise<BookmarkWithDetails[]> {
  if (!supabase) return []

  const userId = await getCurrentUserId()
  const { data: bookmarks, error } = await supabase
    .from('bookmarks')
    .select('*')
    .eq('user_id', userId)
    .order('created_at', { ascending: false })

  if (error) throw error
  if (!bookmarks) return []

  // Fetch related claims and papers
  const claimIds = bookmarks
    .filter((b: Bookmark) => b.claim_id)
    .map((b: Bookmark) => b.claim_id)
  const paperIds = bookmarks
    .filter((b: Bookmark) => b.paper_id)
    .map((b: Bookmark) => b.paper_id)

  const [claimsResult, papersResult] = await Promise.all([
    claimIds.length > 0
      ? supabase.from('claims').select('*').in('id', claimIds)
      : { data: [], error: null },
    paperIds.length > 0
      ? supabase.from('papers').select('*').in('paper_id', paperIds)
      : { data: [], error: null },
  ])

  const claimsMap = new Map((claimsResult.data || []).map((c: Claim) => [c.id, c]))
  const papersMap = new Map((papersResult.data || []).map((p: Paper) => [p.paper_id, p]))

  return bookmarks.map((bookmark: Bookmark) => ({
    ...bookmark,
    claim: bookmark.claim_id ? claimsMap.get(bookmark.claim_id) : undefined,
    paper: bookmark.paper_id ? papersMap.get(bookmark.paper_id) : undefined,
  }))
}

/**
 * Check if an item is bookmarked
 */
export async function isBookmarked(
  type: BookmarkType,
  itemId: number | string
): Promise<boolean> {
  if (!supabase) return false

  const userId = await getCurrentUserId()
  const column = type === 'claim' ? 'claim_id' : 'paper_id'
  const { count, error } = await supabase
    .from('bookmarks')
    .select('*', { count: 'exact', head: true })
    .eq('user_id', userId)
    .eq('bookmark_type', type)
    .eq(column, itemId)

  if (error) return false
  return (count || 0) > 0
}

/**
 * Create a new bookmark
 */
export async function createBookmark(bookmark: Partial<Bookmark>): Promise<Bookmark | null> {
  if (!supabase) return null

  const userId = await getCurrentUserId()

  const insertData = {
    ...bookmark,
    user_id: userId,
  }

  console.log('[createBookmark] Inserting:', JSON.stringify(insertData, null, 2))

  const { data, error } = await supabase
    .from('bookmarks')
    .insert(insertData)
    .select()
    .single()

  if (error) {
    console.error('[createBookmark] Full error:', JSON.stringify(error, null, 2))
    throw error
  }
  return data
}

/**
 * Update a bookmark
 */
export async function updateBookmark(
  bookmarkId: string,
  updates: Partial<Bookmark>
): Promise<Bookmark | null> {
  if (!supabase) return null

  const userId = await getCurrentUserId()
  const { data, error } = await supabase
    .from('bookmarks')
    .update(updates)
    .eq('id', bookmarkId)
    .eq('user_id', userId)
    .select()
    .single()

  if (error) throw error
  return data
}

/**
 * Delete a bookmark
 */
export async function deleteBookmark(bookmarkId: string): Promise<void> {
  if (!supabase) return

  const userId = await getCurrentUserId()
  const { error } = await supabase
    .from('bookmarks')
    .delete()
    .eq('id', bookmarkId)
    .eq('user_id', userId)

  if (error) throw error
}

/**
 * Get bookmarks enabled for quiz mode
 */
export async function getQuizEnabledBookmarks(): Promise<Bookmark[]> {
  if (!supabase) return []

  const userId = await getCurrentUserId()
  const { data, error } = await supabase
    .from('bookmarks')
    .select('*')
    .eq('user_id', userId)
    .eq('quiz_enabled', true)
    .order('last_quizzed_at', { ascending: true, nullsFirst: true })

  if (error) throw error
  return data || []
}

/**
 * Update bookmark quiz stats after answering
 */
export async function updateBookmarkQuizStats(
  bookmarkId: string,
  correct: boolean
): Promise<void> {
  if (!supabase) return

  const { data: bookmark } = await supabase
    .from('bookmarks')
    .select('quiz_score, quiz_count')
    .eq('id', bookmarkId)
    .single()

  if (!bookmark) return

  const newCount = (bookmark.quiz_count || 0) + 1
  const currentScore = bookmark.quiz_score || 0
  const newScore = ((currentScore * (newCount - 1)) + (correct ? 1 : 0)) / newCount

  await supabase
    .from('bookmarks')
    .update({
      quiz_score: newScore,
      quiz_count: newCount,
      last_quizzed_at: new Date().toISOString(),
    })
    .eq('id', bookmarkId)
}

/**
 * Subscribe to bookmark changes (real-time)
 * Note: This subscribes to ALL bookmark changes for the table and filters client-side
 * because the user ID is determined asynchronously
 */
export function subscribeToBookmarks(
  callback: (payload: { eventType: string; bookmark: Bookmark }) => void
) {
  if (!supabase) {
    console.warn('⚠️ Cannot subscribe to bookmark updates: Supabase not configured')
    return () => {}
  }

  // Get current user ID asynchronously and set up filtered callback
  let currentUserId: string | null = null
  getCurrentUserId().then(id => { currentUserId = id })

  const channel = supabase
    .channel('bookmarks_changes')
    .on(
      'postgres_changes',
      {
        event: '*',
        schema: 'public',
        table: 'bookmarks',
      },
      (payload) => {
        // Filter client-side to only process bookmarks for current user
        const bookmark = payload.new as Bookmark
        if (currentUserId && bookmark.user_id === currentUserId) {
          callback({
            eventType: payload.eventType,
            bookmark,
          })
        }
      }
    )
    .subscribe()

  return () => {
    supabase.removeChannel(channel)
  }
}

// ============================================================================
// Chat Session Types
// ============================================================================

export interface ChatSession {
  id: string
  user_id: string
  podcast_id?: string
  claim_id?: string
  title?: string
  started_at: string
  last_activity_at: string
  is_active: boolean
  context_snapshot?: Record<string, unknown>
  created_at: string
}

export interface ChatMessageRecord {
  id: string
  session_id: string
  role: 'user' | 'assistant' | 'system'
  content: string
  playback_timestamp?: string
  playback_timestamp_ms?: number
  sources?: Array<{
    paper_id: string
    paper_title: string
    year: string
    section: string
    relevance_snippet: string
  }>
  rag_query?: string
  model?: string
  // Image support for AI-generated visualizations
  image_url?: string
  image_caption?: string
  created_at: string
}

// ============================================================================
// Chat Session Functions
// ============================================================================

/**
 * Get or create an active chat session for a given episode/claim context
 */
export async function getOrCreateChatSession(
  podcastId: string,
  claimId?: string
): Promise<ChatSession | null> {
  if (!supabase) return null

  const userId = await getCurrentUserId()

  // Try to find an existing active session for this context
  const { data: existingSession, error: findError } = await supabase
    .from('chat_sessions')
    .select('*')
    .eq('user_id', userId)
    .eq('podcast_id', podcastId)
    .eq('is_active', true)
    .order('last_activity_at', { ascending: false })
    .limit(1)
    .maybeSingle()

  if (findError) {
    console.error('Error finding chat session:', findError)
    return null
  }

  // If we found an active session for this episode, use it
  // (only if claim_id matches or both are null)
  if (existingSession) {
    const claimMatches = existingSession.claim_id === claimId ||
                         (!existingSession.claim_id && !claimId)
    if (claimMatches) {
      return existingSession as ChatSession
    }
  }

  // Create a new session
  const { data: newSession, error: createError } = await supabase
    .from('chat_sessions')
    .insert({
      user_id: userId,
      podcast_id: podcastId,
      claim_id: claimId || null,
      is_active: true,
    })
    .select()
    .single()

  if (createError) {
    console.error('Error creating chat session:', createError)
    return null
  }

  return newSession as ChatSession
}

/**
 * Get all chat sessions for the current user
 */
export async function getChatSessions(podcastId?: string): Promise<ChatSession[]> {
  if (!supabase) return []

  const userId = await getCurrentUserId()
  let query = supabase
    .from('chat_sessions')
    .select('*')
    .eq('user_id', userId)
    .order('last_activity_at', { ascending: false })

  if (podcastId) {
    query = query.eq('podcast_id', podcastId)
  }

  const { data, error } = await query
  if (error) {
    console.error('Error fetching chat sessions:', error)
    return []
  }

  return data as ChatSession[]
}

/**
 * Load messages for a chat session
 */
export async function getChatMessages(sessionId: string): Promise<ChatMessageRecord[]> {
  if (!supabase) return []

  const { data, error } = await supabase
    .from('chat_messages')
    .select('*')
    .eq('session_id', sessionId)
    .order('created_at', { ascending: true })

  if (error) {
    console.error('Error fetching chat messages:', error)
    return []
  }

  return data as ChatMessageRecord[]
}

/**
 * Save a message to a chat session
 */
export async function saveChatMessage(
  sessionId: string,
  message: {
    role: 'user' | 'assistant'
    content: string
    playback_timestamp?: string
    sources?: ChatMessageRecord['sources']
    model?: string
  }
): Promise<ChatMessageRecord | null> {
  if (!supabase) return null

  const { data, error } = await supabase
    .from('chat_messages')
    .insert({
      session_id: sessionId,
      ...message,
    })
    .select()
    .single()

  if (error) {
    console.error('Error saving chat message:', error)
    return null
  }

  // Update session's last_activity_at
  await supabase
    .from('chat_sessions')
    .update({ last_activity_at: new Date().toISOString() })
    .eq('id', sessionId)

  return data as ChatMessageRecord
}

/**
 * Close a chat session (mark as inactive)
 */
export async function closeChatSession(sessionId: string): Promise<void> {
  if (!supabase) return

  await supabase
    .from('chat_sessions')
    .update({ is_active: false })
    .eq('id', sessionId)
}

/**
 * Delete a chat session and all its messages
 */
export async function deleteChatSession(sessionId: string): Promise<void> {
  if (!supabase) return

  const userId = await getCurrentUserId()
  const { error } = await supabase
    .from('chat_sessions')
    .delete()
    .eq('id', sessionId)
    .eq('user_id', userId)

  if (error) {
    console.error('Error deleting chat session:', error)
  }
}

// ============================================================================
// Notebook Query Functions
// ============================================================================

/**
 * Get all bookmarks for a specific episode
 */
export async function getBookmarksForEpisode(episodeId: string): Promise<BookmarkWithDetails[]> {
  if (!supabase) return []

  const userId = await getCurrentUserId()
  const { data: bookmarks, error } = await supabase
    .from('bookmarks')
    .select('*')
    .eq('user_id', userId)
    .eq('episode_id', episodeId)
    .order('created_at', { ascending: false })

  if (error) {
    console.error('Error fetching bookmarks for episode:', error)
    return []
  }
  if (!bookmarks) return []

  // Fetch related claims and papers
  const claimIds = bookmarks
    .filter((b: Bookmark) => b.claim_id)
    .map((b: Bookmark) => b.claim_id)
  const paperIds = bookmarks
    .filter((b: Bookmark) => b.paper_id)
    .map((b: Bookmark) => b.paper_id)

  const [claimsResult, papersResult] = await Promise.all([
    claimIds.length > 0
      ? supabase.from('claims').select('*').in('id', claimIds)
      : { data: [], error: null },
    paperIds.length > 0
      ? supabase.from('papers').select('*').in('paper_id', paperIds)
      : { data: [], error: null },
  ])

  const claimsMap = new Map((claimsResult.data || []).map((c: Claim) => [c.id, c]))
  const papersMap = new Map((papersResult.data || []).map((p: Paper) => [p.paper_id, p]))

  return bookmarks.map((bookmark: Bookmark) => ({
    ...bookmark,
    claim: bookmark.claim_id ? claimsMap.get(bookmark.claim_id) : undefined,
    paper: bookmark.paper_id ? papersMap.get(bookmark.paper_id) : undefined,
  }))
}

/**
 * Get episodes that have at least one bookmark (for notebook library)
 */
export async function getEpisodesWithBookmarks(): Promise<EpisodeNotebookStats[]> {
  if (!supabase) return []

  const userId = await getCurrentUserId()

  // Use the view we created in the migration
  const { data, error } = await supabase
    .from('episode_notebook_stats')
    .select('*')
    .eq('user_id', userId)
    .order('last_updated', { ascending: false })

  if (error) {
    console.error('Error fetching episodes with bookmarks:', error)
    // Fallback: aggregate manually
    const { data: bookmarks } = await supabase
      .from('bookmarks')
      .select('episode_id, bookmark_type, created_at')
      .eq('user_id', userId)
      .not('episode_id', 'is', null)
      .neq('episode_id', '')  // Also filter out empty strings

    if (!bookmarks) return []

    // Group by episode_id
    const episodeMap = new Map<string, EpisodeNotebookStats>()
    for (const b of bookmarks) {
      if (!b.episode_id) continue  // Extra safety check for empty strings
      const existing = episodeMap.get(b.episode_id) || {
        episode_id: b.episode_id,
        total_items: 0,
        claim_count: 0,
        paper_count: 0,
        snippet_count: 0,
        ai_insight_count: 0,
        image_count: 0,
        last_updated: b.created_at,
      }
      existing.total_items++
      if (b.bookmark_type === 'claim') existing.claim_count++
      else if (b.bookmark_type === 'paper') existing.paper_count++
      else if (b.bookmark_type === 'snippet') existing.snippet_count++
      else if (b.bookmark_type === 'ai_insight') existing.ai_insight_count++
      else if (b.bookmark_type === 'image') existing.image_count++
      if (b.created_at > existing.last_updated) existing.last_updated = b.created_at
      episodeMap.set(b.episode_id, existing)
    }
    return Array.from(episodeMap.values())
      .sort((a, b) => b.last_updated.localeCompare(a.last_updated))
  }

  // Filter out any entries with empty episode_id (shouldn't happen with proper view, but safety check)
  return (data as EpisodeNotebookStats[]).filter(stat => stat.episode_id && stat.episode_id.length > 0)
}

/**
 * Get notebook synthesis for an episode (cached AI-generated overview)
 */
export async function getNotebookSynthesis(episodeId: string): Promise<NotebookSynthesis | null> {
  if (!supabase) return null

  const userId = await getCurrentUserId()
  const { data, error } = await supabase
    .from('notebook_synthesis')
    .select('*')
    .eq('user_id', userId)
    .eq('episode_id', episodeId)
    .maybeSingle()

  if (error) {
    console.error('Error fetching notebook synthesis:', error)
    return null
  }

  return data as NotebookSynthesis | null
}

/**
 * Save or update notebook synthesis (upsert)
 */
export async function saveNotebookSynthesis(
  episodeId: string,
  synthesis: {
    synthesis_text: string
    themes?: NotebookSynthesisTheme[]
    connections?: NotebookSynthesisConnection[]
    bookmark_count_at_generation: number
    model_used: string
  }
): Promise<NotebookSynthesis | null> {
  if (!supabase) return null

  const userId = await getCurrentUserId()
  const { data, error } = await supabase
    .from('notebook_synthesis')
    .upsert({
      user_id: userId,
      episode_id: episodeId,
      synthesis_text: synthesis.synthesis_text,
      themes: synthesis.themes,
      connections: synthesis.connections,
      bookmark_count_at_generation: synthesis.bookmark_count_at_generation,
      model_used: synthesis.model_used,
      generated_at: new Date().toISOString(),
      is_stale: false,
    }, {
      onConflict: 'user_id,episode_id',
    })
    .select()
    .single()

  if (error) {
    console.error('Error saving notebook synthesis:', error)
    return null
  }

  return data as NotebookSynthesis
}

/**
 * Delete notebook synthesis cache
 */
export async function deleteNotebookSynthesis(episodeId: string): Promise<void> {
  if (!supabase) return

  const userId = await getCurrentUserId()
  const { error } = await supabase
    .from('notebook_synthesis')
    .delete()
    .eq('user_id', userId)
    .eq('episode_id', episodeId)

  if (error) {
    console.error('Error deleting notebook synthesis:', error)
  }
}

// ============================================================================
// Taxonomy Cluster Query Functions
// ============================================================================

/**
 * Get all taxonomy clusters
 */
export async function getTaxonomyClusters(): Promise<TaxonomyCluster[]> {
  if (!supabase) return []

  const { data, error } = await supabase
    .from('taxonomy_clusters')
    .select('*')
    .order('cluster_id')

  if (error) {
    console.error('Error fetching taxonomy clusters:', error)
    return []
  }

  return data as TaxonomyCluster[]
}

/**
 * Get papers assigned to a specific cluster
 */
export async function getClusterPapers(
  clusterId: number,
  limit: number = 20
): Promise<PaperClusterAssignment[]> {
  if (!supabase) return []

  const { data, error } = await supabase
    .from('paper_cluster_assignments')
    .select('*, papers!inner(paper_id, title, abstract, year, citation_count)')
    .eq('cluster_id', clusterId)
    .order('confidence', { ascending: false })
    .limit(limit)

  if (error) {
    console.error('Error fetching cluster papers:', error)
    return []
  }

  return data as PaperClusterAssignment[]
}

/**
 * Get cluster coverage for an episode via RPC
 */
export async function getEpisodeClusterCoverage(
  podcastId: string
): Promise<ClusterCoverage[]> {
  if (!supabase) return []

  const { data, error } = await supabase
    .rpc('get_episode_cluster_coverage', {
      p_podcast_id: podcastId
    })

  if (error) {
    console.error('Error fetching episode cluster coverage:', error)
    return []
  }

  return data as ClusterCoverage[]
}

/**
 * Get notebook cluster distribution via RPC
 */
export async function getNotebookClusterDistribution(
  episodeId?: string
): Promise<NotebookClusterDistribution[]> {
  if (!supabase) return []

  const userId = await getCurrentUserId()
  const params: { p_user_id: string; p_episode_id?: string } = {
    p_user_id: userId
  }
  if (episodeId) {
    params.p_episode_id = episodeId
  }

  const { data, error } = await supabase
    .rpc('get_notebook_cluster_distribution', params)

  if (error) {
    console.error('Error fetching notebook cluster distribution:', error)
    return []
  }

  return data as NotebookClusterDistribution[]
}

/**
 * Compare episode clusters to notebook via RPC
 */
export async function compareEpisodeToNotebook(
  podcastId: string
): Promise<{
  all: EpisodeNotebookComparison[]
  new_clusters: EpisodeNotebookComparison[]
  overlapping: EpisodeNotebookComparison[]
  existing_only: EpisodeNotebookComparison[]
  unexplored: EpisodeNotebookComparison[]
  summary: ClusterComparisonSummary
}> {
  if (!supabase) {
    return {
      all: [],
      new_clusters: [],
      overlapping: [],
      existing_only: [],
      unexplored: [],
      summary: {
        episode_cluster_count: 0,
        notebook_cluster_count: 0,
        new_territory_count: 0,
        overlap_count: 0,
        total_clusters: 0
      }
    }
  }

  const userId = await getCurrentUserId()
  const { data, error } = await supabase
    .rpc('compare_episode_to_notebook', {
      p_podcast_id: podcastId,
      p_user_id: userId
    })

  if (error) {
    console.error('Error comparing episode to notebook:', {
      message: error.message,
      code: error.code,
      details: error.details,
      hint: error.hint,
      fullError: JSON.stringify(error)
    })
    return {
      all: [],
      new_clusters: [],
      overlapping: [],
      existing_only: [],
      unexplored: [],
      summary: {
        episode_cluster_count: 0,
        notebook_cluster_count: 0,
        new_territory_count: 0,
        overlap_count: 0,
        total_clusters: 0
      }
    }
  }

  const all = data as EpisodeNotebookComparison[]
  const new_clusters = all.filter(c => c.in_episode && !c.in_notebook)
  const overlapping = all.filter(c => c.in_episode && c.in_notebook)
  const existing_only = all.filter(c => !c.in_episode && c.in_notebook)
  const unexplored = all.filter(c => !c.in_episode && !c.in_notebook)

  return {
    all,
    new_clusters,
    overlapping,
    existing_only,
    unexplored,
    summary: {
      episode_cluster_count: all.filter(c => c.in_episode).length,
      notebook_cluster_count: all.filter(c => c.in_notebook).length,
      new_territory_count: new_clusters.length,
      overlap_count: overlapping.length,
      total_clusters: all.length
    }
  }
}

/**
 * Get bubble map data for taxonomy visualization
 */
export async function getClusterBubbleMapData(): Promise<ClusterBubbleMapData> {
  if (!supabase) {
    return { nodes: [], bounds: { minX: 0, maxX: 1, minY: 0, maxY: 1 }, cluster_count: 0 }
  }

  const clusters = await getTaxonomyClusters()

  const nodes: ClusterNode[] = clusters.map(c => ({
    id: `cluster-${c.cluster_id}`,
    cluster_id: c.cluster_id,
    type: 'cluster' as const,
    label: c.label,
    description: c.description,
    keywords: c.keywords || [],
    x: c.position_x,
    y: c.position_y,
    size: c.paper_count,
    primaryCount: c.primary_paper_count
  }))

  return {
    nodes,
    bounds: { minX: 0, maxX: 1, minY: 0, maxY: 1 },
    cluster_count: nodes.length
  }
}

// ============================================================================
// Cluster Drill-Down Types and Functions
// ============================================================================

export interface ClaimWithCluster {
  claim_id: number
  claim_text: string
  distilled_claim?: string
  claim_timestamp?: string
  start_ms?: number
  paper_id?: string
  paper_title?: string
  confidence: number
}

export interface BookmarkWithCluster {
  bookmark_id: string
  bookmark_type: string
  claim_id?: number
  paper_id?: string
  episode_id?: string
  title: string
  context_preview?: string
  start_ms?: number
  notes?: string
  created_at: string
  cluster_id: number
  cluster_label: string
  cluster_confidence: number
}

export interface BookmarkClusterMapping {
  bookmark_id: string
  cluster_id: number
  cluster_label: string
  confidence: number
}

/**
 * Get claims for an episode within a specific cluster
 * Used for cluster drill-down in episode overview
 */
export async function getEpisodeClaimsByCluster(
  podcastId: string,
  clusterId: number,
  limit: number = 20
): Promise<ClaimWithCluster[]> {
  if (!supabase) {
    console.warn('[getEpisodeClaimsByCluster] No supabase client')
    return []
  }

  console.log('[getEpisodeClaimsByCluster] Calling RPC with:', { podcastId, clusterId, limit })

  const { data, error } = await supabase
    .rpc('get_episode_claims_by_cluster', {
      p_podcast_id: podcastId,
      p_cluster_id: clusterId,
      p_limit: limit
    })

  if (error) {
    console.error('[getEpisodeClaimsByCluster] Error:', error)
    return []
  }

  console.log('[getEpisodeClaimsByCluster] Got data:', data?.length || 0, 'claims')
  return data as ClaimWithCluster[]
}

/**
 * Get bookmarks filtered by cluster
 * Used for cluster filtering in notebook view
 */
export async function getBookmarksByCluster(
  clusterId: number | null,
  episodeId?: string
): Promise<BookmarkWithCluster[]> {
  if (!supabase) return []

  const userId = await getCurrentUserId()
  const { data, error } = await supabase
    .rpc('get_bookmarks_by_cluster', {
      p_user_id: userId,
      p_cluster_id: clusterId,
      p_episode_id: episodeId || null
    })

  if (error) {
    console.error('Error fetching bookmarks by cluster:', error)
    return []
  }

  return data as BookmarkWithCluster[]
}

/**
 * Get cluster mappings for a list of bookmarks
 * Used for showing cluster badges on bookmark cards
 */
export async function getBookmarkClusterMappings(
  bookmarkIds: string[]
): Promise<Map<string, BookmarkClusterMapping[]>> {
  if (!supabase || bookmarkIds.length === 0) return new Map()

  const { data, error } = await supabase
    .rpc('get_bookmark_cluster_mappings', {
      p_bookmark_ids: bookmarkIds
    })

  if (error) {
    console.error('Error fetching bookmark cluster mappings:', error)
    return new Map()
  }

  // Group by bookmark_id
  const mappings = new Map<string, BookmarkClusterMapping[]>()
  for (const row of data as BookmarkClusterMapping[]) {
    const existing = mappings.get(row.bookmark_id) || []
    existing.push(row)
    mappings.set(row.bookmark_id, existing)
  }

  return mappings
}

// ============================================================================
// Episode Paper Functions
// ============================================================================

export interface EpisodeTopPaper {
  paper_id: string
  title: string
  year: number | null
  citation_count: number | null
  url: string | null
  authors: string[] | null
  reference_count: number  // How many claims in this episode cite this paper
}

/**
 * Get the top papers referenced in an episode, ordered by citation count
 * This finds papers linked through claims and returns the most-cited ones
 */
export async function getTopPapersForEpisode(
  podcastId: string,
  limit: number = 3
): Promise<EpisodeTopPaper[]> {
  if (!supabase) return []

  // First get all unique paper_ids from claims for this episode
  const { data: claims, error: claimsError } = await supabase
    .from('claims')
    .select('paper_id')
    .eq('podcast_id', podcastId)
    .not('paper_id', 'is', null)
    .is('duplicate_of', null)

  if (claimsError) {
    console.error('Error fetching claims for papers:', claimsError)
    return []
  }

  if (!claims || claims.length === 0) return []

  // Count how many times each paper is referenced
  const paperRefCounts = new Map<string, number>()
  for (const claim of claims) {
    if (claim.paper_id) {
      paperRefCounts.set(claim.paper_id, (paperRefCounts.get(claim.paper_id) || 0) + 1)
    }
  }

  const uniquePaperIds = Array.from(paperRefCounts.keys())

  // Get paper details from the papers table
  const { data: papers, error: papersError } = await supabase
    .from('papers')
    .select('paper_id, title, year, citation_count, url, authors')
    .in('paper_id', uniquePaperIds)

  if (papersError) {
    console.error('Error fetching paper details:', papersError)
    return []
  }

  // Sort by reference_count (how many times cited in this episode), then by citation_count as tiebreaker
  return (papers || [])
    .map(p => ({
      paper_id: p.paper_id,
      title: p.title,
      year: p.year,
      citation_count: p.citation_count,
      url: p.url,
      authors: p.authors,
      reference_count: paperRefCounts.get(p.paper_id) || 0
    }))
    .sort((a, b) => {
      // Primary: reference_count descending
      if (b.reference_count !== a.reference_count) {
        return b.reference_count - a.reference_count
      }
      // Secondary: citation_count descending (nulls last)
      const aCitations = a.citation_count ?? -1
      const bCitations = b.citation_count ?? -1
      return bCitations - aCitations
    })
    .slice(0, limit)
}

// ============================================================================
// Example Usage in Components
// ============================================================================

// See frontend/components/listening-view.tsx and frontend/app/page.tsx
// for complete implementation examples using this Supabase client.

